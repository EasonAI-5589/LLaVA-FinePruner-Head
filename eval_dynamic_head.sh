#!/bin/bash

# ========== æ™ºèƒ½æ±‚åŒå­˜å¼‚çš„åŠ¨æ€Headé€‰æ‹©ç­–ç•¥è¯„ä¼°è„šæœ¬ ==========
#
# ğŸ¯ ç”¨é€”ï¼šä¸“é—¨è¯„ä¼°æ™ºèƒ½æ±‚åŒå­˜å¼‚ç­–ç•¥åœ¨å„ä¸ªbenchmarkä¸Šçš„è¡¨ç°
#
# ğŸš€ æ ¸å¿ƒç‰¹æ€§ï¼š
# - ç­–ç•¥è´¨é‡è‡ªé€‚åº”è¯„ä¼° + åŠ¨æ€å…±è¯†é˜ˆå€¼æœºåˆ¶ + å¤æ‚åº¦æ„ŸçŸ¥å¤´æ•°é‡è°ƒæ•´
# - å¤šå±‚æ¬¡å·®å¼‚åŒ–é€‰æ‹© + æ™ºèƒ½æƒé‡èšåˆæœºåˆ¶
# - é¢„æœŸæ€§èƒ½æå‡ï¼š3-6%
#
# ============== è¿è¡Œå•ä¸ªbenchmarkçš„ç¤ºä¾‹å‘½ä»¤ ==============
#
# ğŸ§ª MMEæµ‹è¯• (æ¨èé…ç½®):
# bash eval_dynamic_head.sh mme 128 16
#
# ğŸ§ª POPEæµ‹è¯•:
# bash eval_dynamic_head.sh pope 192 20
#
# ğŸ§ª TextVQAæµ‹è¯•:
# bash eval_dynamic_head.sh textvqa 128 16
#
# ğŸ§ª GQAæµ‹è¯•:
# bash eval_dynamic_head.sh gqa 192 18
#
# ============== è¿è¡Œå®Œæ•´æ¶ˆèç ”ç©¶ ==============
#
# ğŸ”¬ å®Œæ•´è¯„ä¼°æ‰€æœ‰benchmark:
# bash eval_dynamic_head.sh all
#
# ğŸ”¬ åªè¯„ä¼°ç‰¹å®štokené…ç½®:
# bash eval_dynamic_head.sh all 128    # åªæµ‹è¯•128 tokens
# bash eval_dynamic_head.sh all 192    # åªæµ‹è¯•192 tokens
#
# ============== è°ƒè¯•æ¨¡å¼ ==============
#
# ğŸ› å¯ç”¨è¯¦ç»†è°ƒè¯•ä¿¡æ¯:
# DEBUG=true bash eval_dynamic_head.sh mme 128 16
#
# è¿™ä¼šæ˜¾ç¤ºç±»ä¼¼è¾“å‡º:
# ğŸ¯ Intelligent Consensus-Diversity: 17 heads
#    Consensus: 11 | Diversity: 6
#    Dynamic threshold: 0.28 | Complexity: 0.73
#    Strategy qualities: sparsity=0.85, hierarchical=0.72...
#
# ============== ç»“æœè¯„ä¼° ==============
#
# ğŸ“Š æŸ¥çœ‹MMEç»“æœ:
# cd playground/data/eval/MME
# python eval_tool/calculation.py --results_dir answers/llava_mme/llava-v1.5-7b/ablation_a/vtn_128_dynamic
#
# ğŸ“Š æŸ¥çœ‹POPEç»“æœ:
# python llava/eval/eval_pope.py \
#     --annotation-dir playground/data/eval/pope/coco \
#     --question-file playground/data/eval/pope/llava_pope_test.jsonl \
#     --result-file playground/data/eval/pope/answers/.../merge.jsonl
#
# ğŸ“Š æŸ¥çœ‹TextVQAç»“æœ:
# python -m llava.eval.eval_textvqa \
#     --annotation-file playground/data/eval/textvqa/TextVQA_0.5.1_val.json \
#     --result-file playground/data/eval/textvqa/answers/.../merge.jsonl
#
# ğŸ“Š æŸ¥çœ‹GQAç»“æœ:
# python scripts/convert_gqa_for_eval.py --src .../merge.jsonl --dst predictions.json
# cd playground/data/eval/gqa/data && python eval/eval.py --tier testdev_balanced
#
# ============================================================

echo "ğŸš€ å¼€å§‹æ™ºèƒ½æ±‚åŒå­˜å¼‚åŠ¨æ€Headé€‰æ‹©ç­–ç•¥è¯„ä¼°"

# é»˜è®¤å‚æ•°
BENCHMARK=${1:-"mme"}
TOKEN_NUM=${2:-128}
HEAD_NUM=${3:-16}
ENABLE_DEBUG=${DEBUG:-false}

# åŸºç¡€é…ç½®
WORK_DIR="/mnt/bn/bes-nas-zqz-lq-v6arnold6/mlx/users/zhangqizhe/code/VTP/LLaVA-FinePruner-Head"
CKPT_DIR="/mnt/bn/bes-mllm-shared/checkpoint/LLaVA"
DATA_DIR="/mnt/bn/bes-mllm-shared/data/LLaVA/LLaVA-Eval"
CKPT="llava-v1.5-7b"
METHOD="dynamic_head"

echo "åˆ‡æ¢åˆ°å·¥ä½œç›®å½•: ${WORK_DIR}"
cd "${WORK_DIR}" || { echo "âŒ é”™è¯¯: æ— æ³•åˆ‡æ¢åˆ°å·¥ä½œç›®å½•"; exit 1; }

# GPUé…ç½®
if command -v nvidia-smi &> /dev/null; then
    GPU_COUNT=$(nvidia-smi --list-gpus | wc -l)
else
    GPU_COUNT=1
fi

gpu_list=$(seq -s, 0 $((GPU_COUNT-1)))
IFS=',' read -ra GPULIST <<< "$gpu_list"
CHUNKS=${#GPULIST[@]}

echo "æ£€æµ‹åˆ° ${GPU_COUNT} å¼ GPU: ${gpu_list}"

# æ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°å‡½æ•°
run_intelligent_consensus_diversity() {
    local dataset=$1
    local token=$2
    local head=$3
    local param_suffix=$4

    echo "ğŸ¯ è¿è¡Œæ™ºèƒ½æ±‚åŒå­˜å¼‚ç­–ç•¥: ${dataset} | TOKEN=${token} | HEAD=${head}"

    PARAM="vtn_${token}_dynamic${param_suffix}"

    # åŸºç¡€å‘½ä»¤å‚æ•°
    local base_args=(
        --model-path "${CKPT_DIR}/${CKPT}"
        --temperature 0
        --conv-mode vicuna_v1
        --pruning_method "${METHOD}"
        --visual_token_num "${token}"
        --H "${head}"
        --enable-dynamic-selection
    )

    # å¦‚æœå¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œæ·»åŠ debugé…ç½®
    if [ "$ENABLE_DEBUG" = "true" ]; then
        echo "ğŸ› å¯ç”¨è°ƒè¯•æ¨¡å¼"
        export LLAVA_DEBUG_MODE=true
        base_args+=(--debug-mode)
    fi

    case $dataset in
        "mme")
            run_mme_evaluation "$token" "$head" "$PARAM"
            ;;
        "pope")
            run_pope_evaluation "$token" "$head" "$PARAM"
            ;;
        "textvqa")
            run_textvqa_evaluation "$token" "$head" "$PARAM"
            ;;
        "gqa")
            run_gqa_evaluation "$token" "$head" "$PARAM"
            ;;
        *)
            echo "âŒ ä¸æ”¯æŒçš„æ•°æ®é›†: $dataset"
            exit 1
            ;;
    esac
}

# MMEè¯„ä¼°
run_mme_evaluation() {
    local token=$1
    local head=$2
    local param=$3

    echo "ğŸ“Š å¼€å§‹MMEæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°"

    local mme_split="llava_mme"
    local output_dir="./playground/data/eval/MME/answers/${mme_split}/${CKPT}/${METHOD}/${param}"

    mkdir -p "$output_dir"

    # å¹¶è¡Œè¿è¡Œå¤šGPU
    for IDX in $(seq 0 $((CHUNKS-1))); do
        CUDA_VISIBLE_DEVICES=${GPULIST[$IDX]} python -m llava.eval.model_vqa_loader \
            --model-path "${CKPT_DIR}/${CKPT}" \
            --question-file "./playground/data/eval/MME/${mme_split}.jsonl" \
            --image-folder "${DATA_DIR}/MME/MME_Benchmark_release_version" \
            --answers-file "${output_dir}/${CHUNKS}_${IDX}.jsonl" \
            --num-chunks ${CHUNKS} \
            --chunk-idx ${IDX} \
            --pruning_method "${METHOD}" \
            --visual_token_num ${token} \
            --H ${head} \
            --enable-dynamic-selection \
            --temperature 0 \
            --conv-mode vicuna_v1 &
    done

    wait

    # åˆå¹¶ç»“æœ
    local output_file="${output_dir}/merge.jsonl"
    > "$output_file"

    for IDX in $(seq 0 $((CHUNKS-1))); do
        cat "${output_dir}/${CHUNKS}_${IDX}.jsonl" >> "$output_file"
    done

    # MMEåå¤„ç†å’Œè¯„ä¼°
    echo "ğŸ”„ MMEåå¤„ç†å’Œè¯„ä¼°..."
    cd "${WORK_DIR}/playground/data/eval/MME" || exit 1

    python convert_answer_to_mme.py \
        --data_path "${DATA_DIR}/MME" \
        --experiment "${mme_split}/${CKPT}/${METHOD}/${param}/merge"

    cd eval_tool || exit 1
    echo "ğŸ“ˆ MMEæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°ç»“æœ:"
    python calculation.py --results_dir "answers/${mme_split}/${CKPT}/${METHOD}/${param}"

    cd "${WORK_DIR}" || exit 1
    echo "âœ… MMEæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°å®Œæˆ"
}

# POPEè¯„ä¼°
run_pope_evaluation() {
    local token=$1
    local head=$2
    local param=$3

    echo "ğŸ“Š å¼€å§‹POPEæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°"

    local pope_split="llava_pope_test"
    local output_dir="./playground/data/eval/pope/answers/${pope_split}/${CKPT}/${METHOD}/${param}"

    mkdir -p "$output_dir"

    # å¹¶è¡Œè¿è¡Œå¤šGPU
    for IDX in $(seq 0 $((CHUNKS-1))); do
        CUDA_VISIBLE_DEVICES=${GPULIST[$IDX]} python -m llava.eval.model_vqa_loader \
            --model-path "${CKPT_DIR}/${CKPT}" \
            --question-file "./playground/data/eval/pope/${pope_split}.jsonl" \
            --image-folder "${DATA_DIR}/pope/val2014" \
            --answers-file "${output_dir}/${CHUNKS}_${IDX}.jsonl" \
            --num-chunks ${CHUNKS} \
            --chunk-idx ${IDX} \
            --pruning_method "${METHOD}" \
            --visual_token_num ${token} \
            --H ${head} \
            --enable-dynamic-selection \
            --temperature 0 \
            --conv-mode vicuna_v1 &
    done

    wait

    # åˆå¹¶ç»“æœ
    local output_file="${output_dir}/merge.jsonl"
    > "$output_file"

    for IDX in $(seq 0 $((CHUNKS-1))); do
        cat "${output_dir}/${CHUNKS}_${IDX}.jsonl" >> "$output_file"
    done

    # POPEè¯„ä¼°
    echo "ğŸ“ˆ POPEæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°ç»“æœ:"
    python llava/eval/eval_pope.py \
        --annotation-dir "${DATA_DIR}/pope/coco" \
        --question-file "./playground/data/eval/pope/${pope_split}.jsonl" \
        --result-file "$output_file"

    echo "âœ… POPEæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°å®Œæˆ"
}

# TextVQAè¯„ä¼°
run_textvqa_evaluation() {
    local token=$1
    local head=$2
    local param=$3

    echo "ğŸ“Š å¼€å§‹TextVQAæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°"

    local textvqa_split="llava_textvqa_val_v051_ocr"
    local output_dir="./playground/data/eval/textvqa/answers/${textvqa_split}/${CKPT}/${METHOD}/${param}"

    mkdir -p "$output_dir"

    # å¹¶è¡Œè¿è¡Œå¤šGPU
    for IDX in $(seq 0 $((CHUNKS-1))); do
        CUDA_VISIBLE_DEVICES=${GPULIST[$IDX]} python -m llava.eval.model_vqa_loader \
            --model-path "${CKPT_DIR}/${CKPT}" \
            --question-file "./playground/data/eval/textvqa/${textvqa_split}.jsonl" \
            --image-folder "${DATA_DIR}/textvqa/train_images" \
            --answers-file "${output_dir}/${CHUNKS}_${IDX}.jsonl" \
            --num-chunks ${CHUNKS} \
            --chunk-idx ${IDX} \
            --pruning_method "${METHOD}" \
            --visual_token_num ${token} \
            --H ${head} \
            --enable-dynamic-selection \
            --temperature 0 \
            --conv-mode vicuna_v1 &
    done

    wait

    # åˆå¹¶ç»“æœ
    local output_file="${output_dir}/merge.jsonl"
    > "$output_file"

    for IDX in $(seq 0 $((CHUNKS-1))); do
        cat "${output_dir}/${CHUNKS}_${IDX}.jsonl" >> "$output_file"
    done

    # TextVQAè¯„ä¼°
    echo "ğŸ“ˆ TextVQAæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°ç»“æœ:"
    python -m llava.eval.eval_textvqa \
        --annotation-file "${DATA_DIR}/textvqa/TextVQA_0.5.1_val.json" \
        --result-file "$output_file"

    echo "âœ… TextVQAæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°å®Œæˆ"
}

# GQAè¯„ä¼°
run_gqa_evaluation() {
    local token=$1
    local head=$2
    local param=$3

    echo "ğŸ“Š å¼€å§‹GQAæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°"

    local gqa_split="llava_gqa_testdev_balanced"
    local output_dir="./playground/data/eval/gqa/answers/${gqa_split}/${CKPT}/${METHOD}/${param}"

    mkdir -p "$output_dir"

    # å¹¶è¡Œè¿è¡Œå¤šGPU
    for IDX in $(seq 0 $((CHUNKS-1))); do
        CUDA_VISIBLE_DEVICES=${GPULIST[$IDX]} python -m llava.eval.model_vqa_loader \
            --model-path "${CKPT_DIR}/${CKPT}" \
            --question-file "./playground/data/eval/gqa/${gqa_split}.jsonl" \
            --image-folder "${DATA_DIR}/gqa/data/images" \
            --answers-file "${output_dir}/${CHUNKS}_${IDX}.jsonl" \
            --num-chunks ${CHUNKS} \
            --chunk-idx ${IDX} \
            --pruning_method "${METHOD}" \
            --visual_token_num ${token} \
            --H ${head} \
            --enable-dynamic-selection \
            --temperature 0 \
            --conv-mode vicuna_v1 &
    done

    wait

    # åˆå¹¶ç»“æœ
    local output_file="${output_dir}/merge.jsonl"
    > "$output_file"

    for IDX in $(seq 0 $((CHUNKS-1))); do
        cat "${output_dir}/${CHUNKS}_${IDX}.jsonl" >> "$output_file"
    done

    # GQAç‰¹æ®Šå¤„ç†
    echo "ğŸ”„ GQAæ ¼å¼è½¬æ¢å’Œè¯„ä¼°..."
    local gqa_dir="${WORK_DIR}/playground/data/eval/gqa/data"
    local prediction_file="${gqa_dir}/testdev_balanced_predictions_${token}_dynamic.json"

    python scripts/convert_gqa_for_eval.py --src "$output_file" --dst "$prediction_file"

    cd "$gqa_dir" || exit 1
    cp "testdev_balanced_predictions_${token}_dynamic.json" "testdev_balanced_predictions.json"

    echo "ğŸ“ˆ GQAæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°ç»“æœ:"
    python eval/eval.py \
        --path "${DATA_DIR}/gqa/data/questions" \
        --tier testdev_balanced

    rm -f testdev_balanced_predictions.json
    cd "${WORK_DIR}" || exit 1

    echo "âœ… GQAæ™ºèƒ½æ±‚åŒå­˜å¼‚è¯„ä¼°å®Œæˆ"
}

# å®Œæ•´æ¶ˆèç ”ç©¶
run_full_ablation() {
    local specific_token=$1

    echo "ğŸ”¬ å¼€å§‹æ™ºèƒ½æ±‚åŒå­˜å¼‚å®Œæ•´æ¶ˆèç ”ç©¶"

    # æµ‹è¯•é…ç½®
    local token_nums=(192 128 64)
    local head_nums=(24 20 16 12 8)

    # å¦‚æœæŒ‡å®šäº†ç‰¹å®štokenï¼Œåªæµ‹è¯•è¯¥é…ç½®
    if [ -n "$specific_token" ]; then
        token_nums=($specific_token)
        echo "ğŸ¯ åªæµ‹è¯•TOKEN=${specific_token}çš„é…ç½®"
    fi

    for token in "${token_nums[@]}"; do
        for head in "${head_nums[@]}"; do
            echo ""
            echo "ğŸ” è¯„ä¼°é…ç½®: TOKEN=${token}, HEAD=${head} (æ™ºèƒ½æ±‚åŒå­˜å¼‚)"

            # è¿è¡Œæ‰€æœ‰benchmark
            run_intelligent_consensus_diversity "mme" "$token" "$head" "_${head}"
            sleep 2
            run_intelligent_consensus_diversity "pope" "$token" "$head" "_${head}"
            sleep 2
            run_intelligent_consensus_diversity "textvqa" "$token" "$head" "_${head}"
            sleep 2
            run_intelligent_consensus_diversity "gqa" "$token" "$head" "_${head}"
            sleep 5

            echo "âœ… é…ç½® TOKEN=${token}, HEAD=${head} è¯„ä¼°å®Œæˆ"
        done
    done

    echo "âœ… æ™ºèƒ½æ±‚åŒå­˜å¼‚å®Œæ•´æ¶ˆèç ”ç©¶å®Œæˆ!"
}

# ä¸»æ‰§è¡Œé€»è¾‘
case $BENCHMARK in
    "all")
        run_full_ablation "$TOKEN_NUM"
        ;;
    "mme"|"pope"|"textvqa"|"gqa")
        run_intelligent_consensus_diversity "$BENCHMARK" "$TOKEN_NUM" "$HEAD_NUM" ""
        ;;
    *)
        echo "âŒ ä¸æ”¯æŒçš„benchmark: $BENCHMARK"
        echo "æ”¯æŒçš„é€‰é¡¹: mme, pope, textvqa, gqa, all"
        exit 1
        ;;
esac

echo ""
echo "ğŸ‰ æ™ºèƒ½æ±‚åŒå­˜å¼‚åŠ¨æ€Headé€‰æ‹©ç­–ç•¥è¯„ä¼°å®Œæˆ!"
echo ""
echo "ğŸ“Š æŸ¥çœ‹ç»“æœçš„æ–¹æ³•å·²åœ¨è„šæœ¬é¡¶éƒ¨æ³¨é‡Šä¸­è¯¦ç»†è¯´æ˜"
echo "ğŸš€ é¢„æœŸæ€§èƒ½æå‡: 3-6%ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚å¤šæ¨¡æ€ç†è§£ä»»åŠ¡ä¸Š"