# LLaVA-FinePruner-Head é¡¹ç›®è¯´æ˜

è¿™æ˜¯ä¸€ä¸ªåŸºäºLLaVAçš„è§†è§‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¼˜åŒ–é¡¹ç›®ï¼Œä¸»è¦ç ”ç©¶è§†è§‰token pruningå’Œattention headé€‰æ‹©ç­‰ç­–ç•¥ã€‚å¸Œæœ›é€šè¿‡æœ‰æ•ˆçš„æ³¨æ„åŠ›å¤´ç­›é€‰ç­–ç•¥ï¼Œå‡†ç¡®çš„å…³æ³¨åˆ°visual headï¼Œä»è€Œè¿›ä¸€æ­¥æœ‰æ•ˆçš„æŒ‡å¯¼å‰ªæå·¥ä½œï¼Œåœ¨å‰ªæçš„åŒæ—¶å®ç°æ¨¡å‹æ¨ç†åŠ é€Ÿçš„æ•ˆæœ

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°å¹¶å¯¹æ¯”äº†äº†å¤šç§Visual Token Pruningçš„æ–¹æ³•ï¼š

- **FastV**: åŸºäºattention scoreçš„tokené€‰æ‹©
- **SparseVLM**: åŸºäºtext2visual æ³¨æ„åŠ›åˆ†æ•°è¿›è¡Œtokenå‰ªæ
- **PDrop**: åŸºäºDecoding Layerå±‚æ•°è¿›è¡Œçš„å‰ªæ
- VisPruner(å¾…å®Œæˆï¼Œå®Œæˆè¿‡åæ›´æ–°æ–‡æ¡£)
- CDPruner(å¾…å®Œæˆï¼Œå®Œæˆè¿‡åæ›´æ–°æ–‡æ¡£)
- **FastV+FinePruner**: FastVç»“åˆç»†ç²’åº¦headé€‰æ‹©

## ä¸»è¦è„šæœ¬

- `eval.sh`: å®Œæ•´çš„æ¨¡å‹è¯„ä¼°è„šæœ¬ï¼ŒåŒ…å«FastV/SparseVLM/PDropå¯¹æ¯”æ¨¡å‹å’Œå¯¹æ¯”æ–¹æ³•æµ‹è¯•
- `eval_head.sh`: å¤´é€‰æ‹©ç­–ç•¥æ¶ˆèç ”ç©¶è¯„ä¼°è„šæœ¬ï¼Œæ˜¯æˆ‘ä»¬å®éªŒçš„ä¸»è¦
- `enhanced_head_selection.py`: å¢å¼ºçš„å¤´é€‰æ‹©ç­–ç•¥å®ç°

### æ ¸å¿ƒä»£ç 

- `llava/model/language_model/modeling_llama_fastv_fine_head.py`: æ ¸å¿ƒæ¨¡å‹å®ç°ï¼ŒåŒ…å«åŠ¨æ€å¤´é€‰æ‹©
- `llava/eval/`: è¯„ä¼°ç›¸å…³ä»£ç 
- `scripts/v1_5/7b/`: å„æ•°æ®é›†è¯„ä¼°è„šæœ¬

### å®éªŒç»“æœ

- `head_strategy_ablation/`: å¤´é€‰æ‹©ç­–ç•¥æ¶ˆèç ”ç©¶ç»“æœ
- `visualize_head_ablation.py`: ç»“æœå¯è§†åŒ–è„šæœ¬

## å¸¸ç”¨å‘½ä»¤

### è¿è¡Œå®Œæ•´è¯„ä¼°

```bash
bash eval.sh  # è¿è¡ŒFastV/SparseVLM/PDropå®Œæ•´è¯„ä¼°
```

### è¿è¡Œç‰¹å®šæ–¹æ³•è¯„ä¼°

```bash
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 bash scripts/v1_5/7b/[dataset].sh [method] [tokens] [heads]
```

### å¤´é€‰æ‹©ç­–ç•¥æ¶ˆèç ”ç©¶

```bash
bash eval_head.sh
```

## è¯„ä¼°æ•°æ®é›†

æ”¯æŒä»¥ä¸‹10ä¸ªæ•°æ®é›†çš„è¯„ä¼°ï¼š

- VQAv2, GQA, VizWiz, SQA, TextVQA
- POPE, MME, MMBench, MMBench-CN, MMVet

## å‚æ•°é…ç½®

- **tokens**: è§†è§‰tokenæ•°é‡ (64, 128, 192, 576)
- **heads**: attention headæ•°é‡ (8, 16, 24, 32)
- **æ–¹æ³•**: vanilla, fastv, sparsevlm, pdrop, fastv+finepruner

## ç¯å¢ƒè¦æ±‚

- CUDA 8å¡GPUç¯å¢ƒ
- PyTorch + transformers
- LLaVA dependencies

## æ ¸å¿ƒæŠ€æœ¯ï¼šæ™ºèƒ½æ±‚åŒå­˜å¼‚çš„åŠ¨æ€Headé€‰æ‹©ç­–ç•¥

### è®¾è®¡ç†å¿µ

åŸºäº"æ±‚åŒå­˜å¼‚"æ€æƒ³çš„å…¨é¢å‡çº§ç‰ˆæœ¬ï¼Œè§£å†³ä¼ ç»Ÿæ–¹æ³•çš„5å¤§æ ¸å¿ƒé—®é¢˜ï¼š
1. **æ™ºèƒ½æ±‚åŒ**ï¼šç­–ç•¥è´¨é‡åŠ æƒçš„å…±è¯†è¯†åˆ«ï¼Œè€Œéç®€å•æŠ•ç¥¨
2. **ç²¾å‡†å­˜å¼‚**ï¼šå¤šå±‚æ¬¡å·®å¼‚åŒ–é€‰æ‹©ï¼Œç¡®ä¿åŠŸèƒ½ç©ºé—´å…¨è¦†ç›–
3. **è‡ªé€‚åº”é˜ˆå€¼**ï¼šæ ¹æ®ç­–ç•¥ä¸€è‡´æ€§åŠ¨æ€è°ƒæ•´å…±è¯†æ ‡å‡†
4. **å¤æ‚åº¦æ„ŸçŸ¥**ï¼šåŸºäºattention patternå¤æ‚åº¦æ™ºèƒ½ç¡®å®šå¤´æ•°é‡
5. **è´¨é‡é©±åŠ¨**ï¼šå…¨æµç¨‹åŸºäºç­–ç•¥åˆ†è¾¨èƒ½åŠ›å’Œattentionè´¨é‡ä¼˜åŒ–

è¿™ç§æ–¹æ³•çœŸæ­£å®ç°äº†**æ•°æ®é©±åŠ¨ã€è‡ªé€‚åº”ã€æ™ºèƒ½åŒ–**çš„visual headç­›é€‰ã€‚

### æ ¸å¿ƒç®—æ³•ï¼šIntelligent Consensus-Diversity Selection

#### Step 1: ç­–ç•¥è´¨é‡è‡ªé€‚åº”è¯„ä¼°

å¯¹æ¯ä¸ªç­–ç•¥åœ¨å½“å‰attention patternä¸‹è¿›è¡Œè´¨é‡è¯„ä¼°ï¼Œç¡®å®šå…¶å¯ä¿¡åº¦ï¼š

```python
for strategy in all_strategies:
    scores = compute_strategy_scores(image_attention, strategy)

    # å¤šç»´è´¨é‡è¯„ä¼°
    discriminability = scores.std()  # åˆ†æ•°åŒºåˆ†åº¦
    balance = 1.0 - (score_range / score_mean).clamp(0, 1)  # åˆ†å¸ƒåˆç†æ€§
    correlation = F.cosine_similarity(scores, attention_intensity).abs()  # ä¸çœŸå®å¼ºåº¦ç›¸å…³æ€§

    quality = 0.4 * discriminability + 0.3 * balance + 0.3 * correlation

    # æ ¹æ®è´¨é‡ç¡®å®šç²¾ç»†åŒ–é€‰æ‹©æ•°é‡
    if quality > 0.7:
        selection_count = int(H * 0.3)  # é«˜è´¨é‡ç­–ç•¥ç²¾é€‰æ¨¡å¼
    elif quality > 0.4:
        selection_count = H // 2        # æ ‡å‡†æ¨¡å¼
    else:
        selection_count = int(H * 0.65) # å¹¿æ’’ç½‘æ¨¡å¼
```

#### Step 2: åŠ¨æ€å…±è¯†é˜ˆå€¼ä¸è´¨é‡åŠ æƒæŠ•ç¥¨

æ ¹æ®ç­–ç•¥é—´ä¸€è‡´æ€§åŠ¨æ€è°ƒæ•´å…±è¯†æ ‡å‡†ï¼Œç”¨ç­–ç•¥è´¨é‡è¿›è¡ŒåŠ æƒæŠ•ç¥¨ï¼š

```python
# è®¡ç®—ç­–ç•¥é—´ä¸€è‡´æ€§
strategy_consistency = compute_overlap_ratio_across_strategies()

# è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´
if consistency > 0.6:
    dynamic_threshold = min(0.5, base_threshold * (1 + consistency))  # é«˜ä¸€è‡´æ€§æé«˜é˜ˆå€¼
elif consistency < 0.2:
    dynamic_threshold = max(0.15, base_threshold * consistency * 2)   # ä½ä¸€è‡´æ€§é™ä½é˜ˆå€¼
else:
    dynamic_threshold = base_threshold  # æ ‡å‡†é˜ˆå€¼

# è´¨é‡åŠ æƒæŠ•ç¥¨
for strategy, result in strategy_selections.items():
    weight = result['quality']  # ç­–ç•¥è´¨é‡ä½œä¸ºæŠ•ç¥¨æƒé‡
    for head_idx in result['indices']:
        head_weighted_votes[head_idx] += weight
```

#### Step 3: å¤æ‚åº¦æ„ŸçŸ¥çš„å¤´æ•°é‡æ™ºèƒ½ç¡®å®š

åŸºäºattention patternå¤æ‚åº¦ï¼Œæ™ºèƒ½è°ƒæ•´æ‰€éœ€å¤´æ•°é‡ï¼š

```python
# å¤šç»´å¤æ‚åº¦è¯„ä¼°
head_diversity = 1 - avg_similarity_between_heads     # å¤´é—´å¤šæ ·æ€§
attention_entropy = normalized_entropy_across_heads   # åˆ†å¸ƒå¤æ‚åº¦
attention_variance = normalized_variance_of_values    # æ•°å€¼æ–¹å·®

complexity = 0.4 * head_diversity + 0.3 * attention_entropy + 0.3 * attention_variance

# å¤æ‚åº¦è‡ªé€‚åº”è°ƒæ•´
if complexity > 0.7:
    target_count = int(gap_based * (1.2 + 0.3 * complexity))  # é«˜å¤æ‚åº¦éœ€è¦æ›´å¤šå¤´
elif complexity < 0.3:
    target_count = int(gap_based * (0.7 + 0.6 * complexity))  # ä½å¤æ‚åº¦éœ€è¦è¾ƒå°‘å¤´
else:
    target_count = gap_based  # ä¸­ç­‰å¤æ‚åº¦
```

#### Step 4: å¤šå±‚æ¬¡å·®å¼‚åŒ–å¤´é€‰æ‹©

ç¡®ä¿åŠŸèƒ½ç©ºé—´çš„å…¨é¢è¦†ç›–ï¼Œé¿å…å†—ä½™ï¼š

```python
# å±‚æ¬¡1: ä¸å…±è¯†å¤´çš„å·®å¼‚æ€§
diversity_from_consensus = 1 - cosine_similarity(available_heads, consensus_heads)

# å±‚æ¬¡2: å€™é€‰å¤´ä¹‹é—´çš„å¤šæ ·æ€§
for each_remaining_slot:
    if first_diversity_head:
        select_max_diversity_from_consensus()
    else:
        # ç»¼åˆè€ƒè™‘ä¸å…±è¯†å¤´å’Œå·²é€‰å¤´çš„å·®å¼‚æ€§
        diversity_from_selected = 1 - cosine_similarity(candidate, selected_diversity_heads)
        total_score = 0.6 * diversity_from_consensus + 0.4 * diversity_from_selected
        select_max_total_score()
```

#### Step 5: æ™ºèƒ½æƒé‡èšåˆ

åŸºäºå¤´ç±»å‹å’Œè´¨é‡çš„ç²¾ç»†åŒ–æƒé‡åˆ†é…ï¼š

```python
for head_idx in final_indices:
    if head_idx in consensus_heads:
        # å…±è¯†å¤´æƒé‡ï¼šåŸºäºé€‰æ‹©å®ƒçš„ç­–ç•¥è´¨é‡å‡å€¼
        avg_quality = mean([strategy_quality for strategy that selected this head])
        weight = 1.0 + 0.5 * avg_quality
    else:
        # å·®å¼‚åŒ–å¤´æƒé‡ï¼šåŸºäºå…¶attentionè´¨é‡
        attention_quality = normalized_attention_sum(head_idx)
        weight = 0.8 + 0.4 * attention_quality

weights = softmax(all_weights)
```

### æ ¸å¿ƒä¼˜åŠ¿

#### 1. ç­–ç•¥è´¨é‡è‡ªé€‚åº”è¯„ä¼°
- **åˆ›æ–°ç‚¹**ï¼šä¸å†å¹³ç­‰å¯¹å¾…æ‰€æœ‰ç­–ç•¥ï¼Œè€Œæ˜¯è¯„ä¼°æ¯ä¸ªç­–ç•¥åœ¨å½“å‰patternä¸‹çš„æœ‰æ•ˆæ€§
- **æŠ€æœ¯ç»†èŠ‚**ï¼šåŸºäºåˆ†æ•°åŒºåˆ†åº¦ã€åˆ†å¸ƒåˆç†æ€§ã€ä¸çœŸå®attentionçš„ç›¸å…³æ€§è¿›è¡Œå¤šç»´è¯„ä¼°
- **å®é™…æ•ˆæœ**ï¼šé«˜è´¨é‡ç­–ç•¥è·å¾—æ›´å¤šæŠ•ç¥¨æƒé‡å’Œæ›´ç²¾å‡†çš„é€‰æ‹©æ•°é‡

#### 2. åŠ¨æ€å…±è¯†é˜ˆå€¼æœºåˆ¶
- **çªç ´ç‚¹**ï¼šæ‘’å¼ƒå›ºå®š1/3é˜ˆå€¼ï¼Œæ ¹æ®ç­–ç•¥é—´ä¸€è‡´æ€§è‡ªåŠ¨è°ƒæ•´å…±è¯†æ ‡å‡†
- **è‡ªé€‚åº”é€»è¾‘**ï¼šé«˜ä¸€è‡´æ€§åœºæ™¯æé«˜é˜ˆå€¼ï¼ˆç²¾é€‰æ¨¡å¼ï¼‰ï¼Œä½ä¸€è‡´æ€§åœºæ™¯é™ä½é˜ˆå€¼ï¼ˆåŒ…å®¹æ¨¡å¼ï¼‰
- **æ™ºèƒ½åŒ–æ°´å¹³**ï¼šçœŸæ­£å®ç°æ•°æ®é©±åŠ¨çš„é˜ˆå€¼ä¼˜åŒ–

#### 3. å¤æ‚åº¦æ„ŸçŸ¥çš„å¤´æ•°é‡è°ƒæ•´
- **æ ¸å¿ƒç†å¿µ**ï¼šattention patternå¤æ‚åº¦å†³å®šæ‰€éœ€å¤´æ•°é‡ï¼Œè€Œéç›²ç›®å›ºå®šå€¼
- **è¯„ä¼°ç»´åº¦**ï¼šå¤´é—´å¤šæ ·æ€§ + åˆ†å¸ƒç†µ + æ•°å€¼æ–¹å·®çš„ç»¼åˆå¤æ‚åº¦æŒ‡æ ‡
- **åŠ¨æ€èŒƒå›´**ï¼š1-32å…¨èŒƒå›´æ”¯æŒï¼Œå¤æ‚patternä½¿ç”¨æ›´å¤šå¤´ï¼Œç®€å•patternä½¿ç”¨è¾ƒå°‘å¤´

#### 4. å¤šå±‚æ¬¡å·®å¼‚åŒ–é€‰æ‹©
- **è®¾è®¡ç²¾é«“**ï¼šä¸ä»…è€ƒè™‘ä¸å…±è¯†å¤´çš„å·®å¼‚ï¼Œè¿˜ç¡®ä¿å·®å¼‚åŒ–å¤´ä¹‹é—´çš„å¤šæ ·æ€§
- **ç®—æ³•å±‚æ¬¡**ï¼šå±‚æ¬¡1è§£å†³consensus-diversityå·®å¼‚ï¼Œå±‚æ¬¡2è§£å†³diversityå†…éƒ¨å¤šæ ·æ€§
- **åŠŸèƒ½è¦†ç›–**ï¼šç¡®ä¿é€‰ä¸­çš„å¤´è¦†ç›–ä¸åŒçš„visualåŠŸèƒ½ç©ºé—´ï¼Œé¿å…å†—ä½™

#### 5. æ™ºèƒ½æƒé‡èšåˆæœºåˆ¶
- **æƒé‡é€»è¾‘**ï¼šå…±è¯†å¤´åŸºäºç­–ç•¥è´¨é‡è·å¾—æƒé‡å¥–åŠ±ï¼Œå·®å¼‚åŒ–å¤´åŸºäºattentionè´¨é‡è·å¾—æƒé‡
- **å¹³è¡¡è®¾è®¡**ï¼šæ—¢ä½“ç°å…±è¯†å¤´çš„å¹¿æ³›è®¤å¯ï¼Œåˆä¿è¯å·®å¼‚åŒ–å¤´çš„ç‹¬ç‰¹è´¡çŒ®
- **ç²¾ç»†åŒ–æ°´å¹³**ï¼šæ¯ä¸ªå¤´çš„æƒé‡éƒ½æ˜¯åŸºäºå…¶å…·ä½“è´¡çŒ®åŠ¨æ€è®¡ç®—

### å®éªŒé¢„æœŸæ•ˆæœ

åŸºäºæ™ºèƒ½æ±‚åŒå­˜å¼‚çš„5å¤§æŠ€æœ¯çªç ´ï¼Œé¢„æœŸè·å¾—æ˜¾è‘—æ€§èƒ½æå‡ï¼š

#### æ€§èƒ½æå‡é¢„æµ‹
- **ç­–ç•¥è´¨é‡è‡ªé€‚åº”**ï¼šç›¸æ¯”å¹³ç­‰æŠ•ç¥¨æå‡1.5-2.5%
- **åŠ¨æ€å…±è¯†é˜ˆå€¼**ï¼šç›¸æ¯”å›ºå®šé˜ˆå€¼æå‡0.8-1.2%
- **å¤æ‚åº¦æ„ŸçŸ¥è°ƒæ•´**ï¼šç›¸æ¯”å›ºå®šå¤´æ•°æå‡1.0-1.5%
- **å¤šå±‚æ¬¡å·®å¼‚åŒ–**ï¼šç›¸æ¯”ç®€å•å·®å¼‚åŒ–æå‡0.5-1.0%
- **æ™ºèƒ½æƒé‡èšåˆ**ï¼šç›¸æ¯”å›ºå®šæƒé‡æå‡0.3-0.8%

**ç»¼åˆé¢„æœŸæå‡ï¼š3-6%**ï¼Œåœ¨å¤æ‚å¤šæ¨¡æ€ç†è§£ä»»åŠ¡ä¸Šæ•ˆæœæ›´æ˜¾è‘—

#### ç¨³å®šæ€§æ”¹è¿›
- **é²æ£’æ€§**ï¼šç­–ç•¥è´¨é‡è¯„ä¼°ç¡®ä¿åœ¨ä¸åŒattention patternä¸‹çš„ç¨³å®šè¡¨ç°
- **è‡ªé€‚åº”æ€§**ï¼šåŠ¨æ€é˜ˆå€¼å’Œå¤æ‚åº¦æ„ŸçŸ¥é¿å…over-fittingåˆ°ç‰¹å®šåœºæ™¯
- **å¯è§£é‡Šæ€§**ï¼šå…±è¯†æœºåˆ¶æä¾›æ˜ç¡®çš„å¤´é€‰æ‹©ä¾æ®å’Œè´¨é‡è¯„ä¼°

#### æ•ˆç‡ä¼˜åŒ–
- **è®¡ç®—æ•ˆç‡**ï¼šå¤æ‚åº¦æ„ŸçŸ¥é¿å…ä¸å¿…è¦çš„å¤´æ•°é‡æµªè´¹
- **å­˜å‚¨æ•ˆç‡**ï¼šç²¾ç»†åŒ–é€‰æ‹©å‡å°‘å†—ä½™å¤´çš„å­˜å‚¨å¼€é”€
- **æ¨ç†æ•ˆç‡**ï¼šæ™ºèƒ½æƒé‡èšåˆæé«˜attentionèåˆè´¨é‡

### ä½¿ç”¨æ–¹æ³•

```bash
# å¯ç”¨æ™ºèƒ½æ±‚åŒå­˜å¼‚çš„åŠ¨æ€å¤´é€‰æ‹©
python -m llava.eval.model_vqa_loader \
    --pruning_method ablation_a \
    --enable-dynamic-selection \
    --visual_token_num 128 \
    --H 16  # å‚è€ƒå€¼ï¼Œå®é™…ä¼šåŸºäºå¤æ‚åº¦åœ¨1-32èŒƒå›´å†…æ™ºèƒ½è°ƒæ•´
```

### æ ¸å¿ƒå‚æ•°è¯´æ˜

- `--enable-dynamic-selection`: å¯ç”¨æ™ºèƒ½æ±‚åŒå­˜å¼‚çš„5ç»´ä¼˜åŒ–ç­–ç•¥
- `--visual_token_num`: è§†è§‰tokenæ•°é‡ (64/128/192/576)
- `--H`: å¤´æ•°é‡å‚è€ƒå€¼ï¼Œç®—æ³•ä¼šåŸºäºattentionå¤æ‚åº¦æ™ºèƒ½ç¡®å®šæœ€ç»ˆæ•°é‡

### å®éªŒéªŒè¯

#### åŸºç¡€éªŒè¯é…ç½®
```bash
# éªŒè¯1: æ ‡å‡†é…ç½® (é¢„æœŸæ™ºèƒ½é€‰æ‹©10-20ä¸ªheads)
--visual_token_num 128 --enable-dynamic-selection

# éªŒè¯2: é«˜å¤æ‚åº¦åœºæ™¯ (é¢„æœŸæ™ºèƒ½é€‰æ‹©16-28ä¸ªheads)
--visual_token_num 192 --enable-dynamic-selection

# éªŒè¯3: ä½å¤æ‚åº¦åœºæ™¯ (é¢„æœŸæ™ºèƒ½é€‰æ‹©6-14ä¸ªheads)
--visual_token_num 64 --enable-dynamic-selection
```

#### é«˜çº§è°ƒè¯•æ¨¡å¼

å¯ç”¨è¯¦ç»†è°ƒè¯•ä¿¡æ¯æŸ¥çœ‹æ™ºèƒ½é€‰æ‹©è¿‡ç¨‹ï¼š
```python
# åœ¨configä¸­æ·»åŠ 
model.config.debug_mode = True
```

#### è°ƒè¯•è¾“å‡ºç¤ºä¾‹
```
ğŸ¯ Intelligent Consensus-Diversity: 17 heads
   Consensus: 11 | Diversity: 6
   Dynamic threshold: 0.28 | Complexity: 0.73
   Strategy qualities: sparsity=0.85, hierarchical=0.72, graph_based=0.45...
   Selected consensus heads: [2, 7, 12, 16, 19, 23, 28, 30, 31, 14, 25]
   Selected diversity heads: [5, 9, 18, 22, 26, 29]
```

### æ€§èƒ½ç›‘æ§

æ·»åŠ æ€§èƒ½æŒ‡æ ‡ç›‘æ§ï¼š
```python
# å¯é€‰ï¼šæ·»åŠ attentionè´¨é‡ç›‘æ§
model.config.monitor_attention_quality = True
```

è¿™å°†è¾“å‡ºï¼š
- ç­–ç•¥è´¨é‡åˆ†å¸ƒ
- å…±è¯†å¤´vså·®å¼‚åŒ–å¤´çš„è´¡çŒ®æ¯”ä¾‹
- attentionå¤æ‚åº¦å˜åŒ–è¶‹åŠ¿
- å¤´æ•°é‡è‡ªé€‚åº”è½¨è¿¹
